{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2136b38ad1264071af9e31bad7ae9d01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1510cc199aa7459db6a4d674074f689f",
              "IPY_MODEL_834ec2c7eaf741efbde02c707b63d378",
              "IPY_MODEL_a55b5272a2e8470cadba478f6ef435a9"
            ],
            "layout": "IPY_MODEL_e22caac80a494ccfb2c9cf3a324585bc"
          }
        },
        "1510cc199aa7459db6a4d674074f689f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ad533cb00644fb78dee828d7ce84975",
            "placeholder": "​",
            "style": "IPY_MODEL_7e39fc0872ff4470959dc13a1bc48957",
            "value": "100%"
          }
        },
        "834ec2c7eaf741efbde02c707b63d378": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b31062964d2e49e4b646978485805e7a",
            "max": 87306240,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a8fe07243ea84b429d094c629bb5ef9b",
            "value": 87306240
          }
        },
        "a55b5272a2e8470cadba478f6ef435a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_136031e5db494d5f858db757709ca4c8",
            "placeholder": "​",
            "style": "IPY_MODEL_130ec30f81bf4317ac2413964920c09c",
            "value": " 83.3M/83.3M [00:01&lt;00:00, 96.6MB/s]"
          }
        },
        "e22caac80a494ccfb2c9cf3a324585bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ad533cb00644fb78dee828d7ce84975": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e39fc0872ff4470959dc13a1bc48957": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b31062964d2e49e4b646978485805e7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8fe07243ea84b429d094c629bb5ef9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "136031e5db494d5f858db757709ca4c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "130ec30f81bf4317ac2413964920c09c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install albumentations==1.2.1\n",
        "!pip install openvino\n",
        "!pip install segmentation_models_pytorch\n",
        "!pip install torch-lr-finder\n",
        "from torch_lr_finder import LRFinder\n",
        "import segmentation_models_pytorch as smp\n",
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms.functional as TF\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import zipfile\n",
        "import random\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "from google.colab.patches import cv2_imshow\n",
        "import gc\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "os.environ['PYTHONHASHSEED'] = str(27)\n",
        "random.seed(27)\n",
        "np.random.seed(27)\n",
        "torch.manual_seed(27)\n",
        "torch.cuda.manual_seed(27)\n",
        "torch.cuda.manual_seed_all(27)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "wetBgfF9g-9Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c18a2b2e-ab51-484e-aa7d-eee9c94c85bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: albumentations==1.2.1 in /usr/local/lib/python3.7/dist-packages (1.2.1)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==1.2.1) (4.6.0.66)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==1.2.1) (0.18.3)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==1.2.1) (1.21.6)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from albumentations==1.2.1) (0.0.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations==1.2.1) (6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations==1.2.1) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from qudida>=0.0.4->albumentations==1.2.1) (1.0.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from qudida>=0.0.4->albumentations==1.2.1) (4.1.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations==1.2.1) (7.1.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations==1.2.1) (2.9.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations==1.2.1) (2021.11.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations==1.2.1) (2.6.3)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations==1.2.1) (1.3.0)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations==1.2.1) (3.2.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations==1.2.1) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations==1.2.1) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations==1.2.1) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations==1.2.1) (3.0.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations==1.2.1) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.2.1) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.2.1) (1.2.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openvino\n",
            "  Downloading openvino-2022.2.0-7713-cp37-cp37m-manylinux_2_27_x86_64.whl (26.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 26.8 MB 56.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<=1.23.1,>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from openvino) (1.21.6)\n",
            "Installing collected packages: openvino\n",
            "Successfully installed openvino-2022.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting segmentation_models_pytorch\n",
            "  Downloading segmentation_models_pytorch-0.3.0-py3-none-any.whl (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 5.2 MB/s \n",
            "\u001b[?25hCollecting timm==0.4.12\n",
            "  Downloading timm-0.4.12-py3-none-any.whl (376 kB)\n",
            "\u001b[K     |████████████████████████████████| 376 kB 51.3 MB/s \n",
            "\u001b[?25hCollecting efficientnet-pytorch==0.7.1\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "Collecting pretrainedmodels==0.7.4\n",
            "  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from segmentation_models_pytorch) (0.13.1+cu113)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from segmentation_models_pytorch) (4.64.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from segmentation_models_pytorch) (7.1.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (1.12.1+cu113)\n",
            "Collecting munch\n",
            "  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (4.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from munch->pretrainedmodels==0.7.4->segmentation_models_pytorch) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (2.10)\n",
            "Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16446 sha256=db00653724a00c02ebd3c220c8b94f7e85a749706f1975f19b550ab01449e7bb\n",
            "  Stored in directory: /root/.cache/pip/wheels/0e/cc/b2/49e74588263573ff778da58cc99b9c6349b496636a7e165be6\n",
            "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60965 sha256=f4a62e583cbcb44af339510c40c498e22ca871c9f3b119c3db17d2d98c16b464\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/27/e8/9543d42de2740d3544db96aefef63bda3f2c1761b3334f4873\n",
            "Successfully built efficientnet-pytorch pretrainedmodels\n",
            "Installing collected packages: munch, timm, pretrainedmodels, efficientnet-pytorch, segmentation-models-pytorch\n",
            "Successfully installed efficientnet-pytorch-0.7.1 munch-2.5.0 pretrainedmodels-0.7.4 segmentation-models-pytorch-0.3.0 timm-0.4.12\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch-lr-finder\n",
            "  Downloading torch_lr_finder-0.2.1-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (21.3)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (1.12.1+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (1.21.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (3.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->torch-lr-finder) (4.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torch-lr-finder) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torch-lr-finder) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torch-lr-finder) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torch-lr-finder) (1.4.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->torch-lr-finder) (1.15.0)\n",
            "Installing collected packages: torch-lr-finder\n",
            "Successfully installed torch-lr-finder-0.2.1\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed=27):\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "FpDkMgXfhrpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zipFile = zipfile.ZipFile('/content/drive/MyDrive/Datasets/synthetic.zip', 'r')\n",
        "zipFile.extractall('dataset')\n",
        "zipFile.close()"
      ],
      "metadata": {
        "id": "htKpIWqhg8E1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mean_and_std(data_loader):\n",
        "  mean = 0\n",
        "  std = 0\n",
        "  images_count = 0\n",
        "  for images, _ in data_loader:\n",
        "    \n",
        "    images_in_the_batch = images.size(0)\n",
        "    images = images.view(images_in_the_batch, images.size(1), -1)\n",
        "    mean += images.mean(2).sum(0)\n",
        "    std += images.std(2).sum(0)\n",
        "    images_count += images_in_the_batch\n",
        "  \n",
        "  mean /= images_count\n",
        "  std /= images_count\n",
        "  \n",
        "  return mean, std"
      ],
      "metadata": {
        "id": "kMIFskT-hDyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = open(\"/content/dataset/synthetic/lists/train_lst.txt\")\n",
        "text = file.read()\n",
        "file.close()\n",
        "arr = text.split('\\n')\n",
        "if '' in arr:\n",
        "  arr.remove('')\n",
        "image_path = \"/content/dataset/synthetic/images\"\n",
        "masks_path = \"/content/dataset/synthetic/masks\"\n",
        "img_path = image_path+\"/Img_\"+arr[23]+\".jpeg\"\n",
        "mask_path = masks_path+\"/Mask_\"+arr[23]+\".png\"\n",
        "image = np.array(Image.open(img_path).convert(\"RGB\"))\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "mask = np.array(Image.open(mask_path).convert(\"L\"), dtype=np.float32)\n",
        "# mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
        "mask = cv2.resize(mask, (100,100))\n",
        "# cv2_imshow(image)\n",
        "mask[mask == 107] = 0\n",
        "mask[mask == 195] = 1\n",
        "mask[mask == 88] = 2\n",
        "mask[mask == 70] = 3\n",
        "mask[mask == 225] = 4\n",
        "# np.eye(5, dtype='uint8')[mask]\n",
        "# cv2_imshow(mask)\n",
        "print(mask.shape)\n",
        "\n",
        "# 0 vista = 107\n",
        "# 1 building = 195\n",
        "# 2 road = 88\n",
        "# 3 tree = 70\n",
        "# 4 cable = 225"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drYDdujehITE",
        "outputId": "811cf232-6567-426f-c479-165c986d835c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "COLORS = np.array([\n",
        "    [150,  95,  60], # 0 vista\n",
        "    [195, 195, 195], # 1 building\n",
        "    [ 88,  88,  88], # 2 road\n",
        "    [  0, 120,   0], # 3 tree\n",
        "    [255, 255,   0], # 4 cable\n",
        "], dtype=np.uint8)"
      ],
      "metadata": {
        "id": "M99MYtfomN0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model"
      ],
      "metadata": {
        "id": "HTA5C7KSY-xp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv_block(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "    self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "    self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    x = self.conv1(inputs)\n",
        "    x = self.bn1(x)\n",
        "    x = self.relu(x)\n",
        "\n",
        "    x = self.conv2(x)\n",
        "    x = self.bn2(x)\n",
        "    x = self.relu(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "class SqueezeExcitation(nn.Module):\n",
        "    def __init__(self, in_channels, reduced_dim):\n",
        "        super(SqueezeExcitation, self).__init__()\n",
        "        self.se = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1), # C x H x W -> C x 1 x 1\n",
        "            nn.Conv2d(in_channels, reduced_dim, 1),\n",
        "            nn.SiLU(),\n",
        "            nn.Conv2d(reduced_dim, in_channels, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x * self.se(x)\n",
        "\n",
        "class Downsample(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv = Conv_block(in_channels, out_channels)\n",
        "    self.pool = nn.MaxPool2d((2, 2))\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    x = self.conv(inputs)\n",
        "    p = self.pool(x)\n",
        "\n",
        "    return x, p\n",
        "\n",
        "\n",
        "class Upsample(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super().__init__()\n",
        "\n",
        "    self.up = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2, padding=0)\n",
        "    self.conv = Conv_block(out_channels + out_channels, out_channels)\n",
        "    self.attention = SqueezeExcitation(out_channels, out_channels//2)\n",
        "\n",
        "  def forward(self, inputs, skip):\n",
        "    x = self.up(inputs)\n",
        "    if x.shape != skip.shape:\n",
        "      x = TF.resize(x, size=skip.shape[2:])\n",
        "    x = torch.cat([x, skip], axis=1)\n",
        "    x = self.conv(x)\n",
        "    x = self.attention(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "class unet(nn.Module):\n",
        "  def __init__(self, num_classes = 5):\n",
        "    super().__init__()\n",
        "\n",
        "\n",
        "    self.down1 = Downsample(3, 64)\n",
        "    self.down2 = Downsample(64, 128)\n",
        "    self.down3 = Downsample(128, 256)\n",
        "    self.down4 = Downsample(256, 512)\n",
        "\n",
        "\n",
        "    self.transition = Conv_block(512, 1024)\n",
        "\n",
        "\n",
        "    self.up1 = Upsample(1024, 512)\n",
        "    self.up2 = Upsample(512, 256)\n",
        "    self.up3 = Upsample(256, 128)\n",
        "    self.up4 = Upsample(128, 64)\n",
        "\n",
        "   \n",
        "    self.outputs = nn.Conv2d(64, num_classes, kernel_size=1, padding=0)\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    skip1, x = self.down1(inputs)\n",
        "    skip2, x = self.down2(x)\n",
        "    skip3, x = self.down3(x)\n",
        "    skip4, x = self.down4(x)\n",
        "\n",
        "\n",
        "    x = self.transition(x)\n",
        "\n",
        "\n",
        "    x = self.up1(x, skip4)\n",
        "    x = self.up2(x, skip3)\n",
        "    x = self.up3(x, skip2)\n",
        "    x = self.up4(x, skip1)\n",
        "\n",
        "\n",
        "    outputs = self.outputs(x)\n",
        "\n",
        "    return outputs"
      ],
      "metadata": {
        "id": "PeeWl8p4poXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Assets"
      ],
      "metadata": {
        "id": "mCEaYFbib-4K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_checkpoint(state, filename=\"my_checkpoint.pth.tar\"):\n",
        "    print(\"=> Saving checkpoint\")\n",
        "    torch.save(state, filename)\n",
        "\n",
        "def load_checkpoint(checkpoint, model):\n",
        "    print(\"=> Loading checkpoint\")\n",
        "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "\n",
        "def check_accuracy(loader, model, device=\"cuda\"):\n",
        "    num_correct = 0\n",
        "    num_pixels = 0\n",
        "    dice_score = 0\n",
        "    jaccard_idx = 0\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            preds = torch.softmax(model(x), 1)\n",
        "            _, preds = torch.max(preds, dim=1)\n",
        "            preds = preds.type(torch.float)\n",
        "            num_correct += (preds == y).sum()\n",
        "            num_pixels += torch.numel(preds)\n",
        "            dice_score += (2 * num_correct +1e-8) / (\n",
        "                2 * num_correct + num_pixels - num_correct + 1e-8\n",
        "            )\n",
        "            jaccard_idx += (num_correct + 1e-8) / (\n",
        "                num_correct + (preds != y).sum()+ 1e-8\n",
        "            )\n",
        "    acc = num_correct/num_pixels\n",
        "    print(\n",
        "        f\"Got {num_correct}/{num_pixels} with acc {num_correct/num_pixels*100:.2f}\"\n",
        "    )\n",
        "    dice = dice_score/len(loader)\n",
        "    print(f\"Dice score: {dice_score/len(loader)}\")\n",
        "\n",
        "    jaccard = jaccard_idx/len(loader)\n",
        "    print(f\"Jaccard index: {jaccard}\")\n",
        "    model.train()\n",
        "\n",
        "    return acc, dice, jaccard\n",
        "\n",
        "def save_predictions_as_imgs(\n",
        "    loader, model, folder=\"saved_images/\", device=\"cuda\"\n",
        "):\n",
        "    model.eval()\n",
        "    for idx, (x, y) in enumerate(loader):\n",
        "        x = x.to(device=device)\n",
        "        with torch.no_grad():\n",
        "            preds = torch.sigmoid(model(x))\n",
        "            preds = (preds > 0.5).float()\n",
        "        torchvision.utils.save_image(\n",
        "            preds, f\"{folder}/pred_{idx}.png\"\n",
        "        )\n",
        "        torchvision.utils.save_image(y.unsqueeze(1), f\"{folder}{idx}.png\")\n",
        "\n",
        "    model.train()"
      ],
      "metadata": {
        "id": "k3lElQTCtRLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Datasets and data loaders"
      ],
      "metadata": {
        "id": "v-buuXgSZF0O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SyntheticDataset(Dataset):\n",
        "  def __init__(self, list_path, dir=\"/content/dataset/synthetic\", transform=None ):\n",
        "    self.file_path = list_path\n",
        "    self.dir = dir\n",
        "    self.transforms = transform\n",
        "    self.images_path = self.dir+\"/images\"\n",
        "    self.masks_path = self.dir+\"/masks\"\n",
        "    self.file = open(self.file_path, encoding='utf-8')\n",
        "    self.text = self.file.read()\n",
        "    self.file.close\n",
        "    self.image_descriptions = self.text.split(\"\\n\")\n",
        "    if '' in self.image_descriptions:\n",
        "      self.image_descriptions.remove('')\n",
        "    \n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    img_path = self.images_path+\"/Img_\"+self.image_descriptions[index]+\".jpeg\"\n",
        "    mask_path = self.masks_path+\"/Mask_\"+self.image_descriptions[index]+\".png\"\n",
        "    image = np.array(Image.open(img_path).convert(\"RGB\"))\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    mask = np.array(Image.open(mask_path).convert(\"L\"))\n",
        "    mask[mask == 107] = 0\n",
        "    mask[mask == 195] = 1\n",
        "    mask[mask == 88] = 2\n",
        "    mask[mask == 70] = 3\n",
        "    mask[mask == 225] = 4\n",
        "    \n",
        "    if self.transforms is not None:\n",
        "      augmentations = self.transforms(image=image, mask=mask)\n",
        "      image = augmentations[\"image\"]\n",
        "      mask = augmentations[\"mask\"]\n",
        "    return image, mask\n",
        "\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.image_descriptions)"
      ],
      "metadata": {
        "id": "zhHhH-l4qJTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed_everything()\n",
        "WEIGHT_DECAY = 1e-4\n",
        "LEARNING_RATE = 3e-4\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "BATCH_SIZE = 4\n",
        "NUM_EPOCHS = 30\n",
        "NUM_WORKERS = 2\n",
        "IMAGE_HEIGHT = 720  # 1080 originally\n",
        "IMAGE_WIDTH = 1088  # 1920 originally\n",
        "PIN_MEMORY = True\n",
        "LOAD_MODEL = False"
      ],
      "metadata": {
        "id": "M8MUzei6uNOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed_everything()\n",
        "mean = [0.5585, 0.6353, 0.6439]\n",
        "std = [0.1218, 0.1545, 0.1860]\n",
        "train_transforms1 = A.Compose(\n",
        "        [\n",
        "            A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
        "            A.Rotate(limit=35, p=1.0),\n",
        "            A.HorizontalFlip(p=0.9),\n",
        "            A.VerticalFlip(p=0.9),\n",
        "            A.Normalize(\n",
        "                mean=mean,\n",
        "                std=std,\n",
        "                max_pixel_value=255.0,\n",
        "            ),\n",
        "            ToTensorV2(),\n",
        "        ],\n",
        "    )\n",
        "\n",
        "train_transforms2 = A.Compose(\n",
        "        [\n",
        "            A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
        "            # A.RGBShift(r_shift_limit=25, g_shift_limit=25, b_shift_limit=25),\n",
        "            # A.Blur(blur_limit=5, p=0.7),\n",
        "            # A.RandomBrightnessContrast(p=0.5),\n",
        "            # A.ChannelShuffle(p=0.7),\n",
        "            # A.Solarize(threshold=128, p=0.5),\n",
        "            # A.GaussNoise(),\n",
        "            # A.InvertImg(p=0.7),\n",
        "            A.Normalize(\n",
        "                mean=mean,\n",
        "                std=std,\n",
        "                max_pixel_value=255.0,\n",
        "            ),\n",
        "            ToTensorV2(),\n",
        "        ],\n",
        "    )\n",
        "\n",
        "train_transforms3 = A.Compose(\n",
        "        [\n",
        "            A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
        "            # A.RGBShift(r_shift_limit=25, g_shift_limit=25, b_shift_limit=25),\n",
        "            # A.Blur(blur_limit=5, p=0.7),\n",
        "            # A.RandomBrightnessContrast(p=0.5),\n",
        "            # A.ChannelShuffle(p=0.7),\n",
        "            A.Solarize(threshold=128, p=0.5),\n",
        "            A.GaussNoise(),\n",
        "            A.InvertImg(p=0.7),\n",
        "            A.Normalize(\n",
        "                mean=mean,\n",
        "                std=std,\n",
        "                max_pixel_value=255.0,\n",
        "            ),\n",
        "            ToTensorV2(),\n",
        "        ],\n",
        "    )\n",
        "val_transforms = A.Compose(\n",
        "        [\n",
        "            A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
        "            A.Normalize(\n",
        "                mean=mean,\n",
        "                std=std,\n",
        "                max_pixel_value=255.0,\n",
        "            ),\n",
        "            ToTensorV2(),\n",
        "        ],\n",
        "    )"
      ],
      "metadata": {
        "id": "-FJzT_bvqDUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed_everything()\n",
        "train_dataset1 = SyntheticDataset(\n",
        "        list_path = \"/content/dataset/synthetic/lists/train_lst.txt\",\n",
        "        transform=train_transforms1,\n",
        "    )\n",
        "\n",
        "train_dataset2 = SyntheticDataset(\n",
        "        list_path = \"/content/dataset/synthetic/lists/train_lst.txt\",\n",
        "        transform=train_transforms2,\n",
        "    )\n",
        "\n",
        "train_dataset3 = SyntheticDataset(\n",
        "        list_path = \"/content/dataset/synthetic/lists/train_lst.txt\",\n",
        "        transform=train_transforms3,\n",
        "    )\n",
        "\n",
        "train_dataset = torch.utils.data.ConcatDataset([train_dataset1, train_dataset2, train_dataset3])\n",
        "\n",
        "train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=PIN_MEMORY,\n",
        "        shuffle=True,\n",
        "    )\n",
        "\n",
        "val_dataset = SyntheticDataset(\n",
        "        list_path = \"/content/dataset/synthetic/lists/val_lst.txt\",\n",
        "        transform=val_transforms,\n",
        "    )\n",
        "\n",
        "val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=PIN_MEMORY,\n",
        "        shuffle=False,\n",
        "    )"
      ],
      "metadata": {
        "id": "6OGKV1ovuMM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training"
      ],
      "metadata": {
        "id": "f6yHIRAnZN63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_fn(loader, model, optimizer, loss_fn, scaler):\n",
        "    seed_everything()\n",
        "    loop = tqdm(loader)\n",
        "\n",
        "    for batch_idx, (data, targets) in enumerate(loop):\n",
        "        data = data.to(device=DEVICE)\n",
        "        targets = targets.type(torch.LongTensor)\n",
        "        targets = targets.to(device=DEVICE)\n",
        "\n",
        "        # forward\n",
        "        with torch.cuda.amp.autocast():\n",
        "            predictions = model(data)\n",
        "            loss = loss_fn(predictions, targets)\n",
        "        # predictions = model(data)\n",
        "        # loss = loss_fn(predictions, targets)\n",
        "\n",
        "        # backward\n",
        "        # loss.backward()\n",
        "        # optimizer.step()\n",
        "        # optimizer.zero_grad()\n",
        "        optimizer.zero_grad()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        # update tqdm loop\n",
        "        loop.set_postfix(loss=loss.item())"
      ],
      "metadata": {
        "id": "UVpRmpjhuIGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "DrtoZUWeDs1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed_everything()\n",
        "weights = torch.tensor([0.4, 1.5, 0.7, 0.4, 1.5], device=DEVICE)\n",
        "model = smp.DeepLabV3Plus(classes=5, encoder_weights=\"imagenet\")\n",
        "model = model.to(DEVICE)\n",
        "# loss_fn = nn.CrossEntropyLoss(weight = weights)\n",
        "loss_fn1 = smp.losses.DiceLoss(\"multiclass\")\n",
        "loss_fn2 = nn.CrossEntropyLoss(weight = weights)\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "# lr_finder = LRFinder(model, optimizer, loss_fn, device=\"cuda\")\n",
        "# lr_finder.range_test(train_loader, end_lr=1, num_iter=1000)\n",
        "# lr_finder.plot()"
      ],
      "metadata": {
        "id": "DqiTsLtHYpDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 0 vista = 107\n",
        "# 1 building = 195\n",
        "# 2 road = 88\n",
        "# 3 tree = 70\n",
        "# 4 cable = 225\n",
        "seed_everything()\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "writer = SummaryWriter(\"/content/boards/board\")\n",
        "step = 0\n",
        "sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, LEARNING_RATE, epochs=NUM_EPOCHS, \n",
        "                                               steps_per_epoch=len(train_loader))\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  # train_fn(train_loader, model, optimizer, loss_fn, scaler)\n",
        "  loop = tqdm(train_loader)\n",
        "\n",
        "  for batch_idx, (data, targets) in enumerate(loop):\n",
        "      data = data.to(device=DEVICE)\n",
        "      targets = targets.type(torch.LongTensor)\n",
        "      targets = targets.to(device=DEVICE)\n",
        "\n",
        "\n",
        "      predictions = model(data)\n",
        "      loss = 0.4*loss_fn1(predictions, targets) + 0.8*loss_fn2(predictions, targets)\n",
        "\n",
        "      # backward\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "\n",
        "      sched.step()\n",
        "      # update tqdm loop\n",
        "      loop.set_postfix(loss=loss.item())\n",
        "\n",
        "\n",
        "  val_acc, dice_score, jaccard_idx = check_accuracy(val_loader, model, device=DEVICE)\n",
        "  if dice_score > 0.9815:\n",
        "    torch.save(model, f\"Synthetic_sementation_deeplabv3plus_val_acc={val_acc}_dice={dice_score}_Jaccard={jaccard_idx}\")\n",
        "\n",
        "\n",
        "  writer.add_scalar(\"Validation accuracy\", val_acc, global_step=step)\n",
        "  writer.add_scalar(\"Dice score\", dice_score, global_step=step)\n",
        "  writer.add_scalar(\"Jaccard index\", jaccard_idx, global_step=step) \n",
        "  step += 1\n",
        "  \n",
        "writer.close()"
      ],
      "metadata": {
        "id": "C4EeFYfh-8rQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67b3a6c9-f79f-48ca-a358-cda88d0df86c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [01:04<00:00,  1.16it/s, loss=1.12]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 8716429/12533760 with acc 69.54\n",
            "Dice score: 0.8142071962356567\n",
            "Jaccard index: 0.8180963397026062\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [01:04<00:00,  1.17it/s, loss=0.68]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 11010199/12533760 with acc 87.84\n",
            "Dice score: 0.9294045567512512\n",
            "Jaccard index: 0.9295482635498047\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [01:04<00:00,  1.17it/s, loss=0.348]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 11469707/12533760 with acc 91.51\n",
            "Dice score: 0.9533284902572632\n",
            "Jaccard index: 0.9527910947799683\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [01:04<00:00,  1.17it/s, loss=0.275]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 11681220/12533760 with acc 93.20\n",
            "Dice score: 0.9622743129730225\n",
            "Jaccard index: 0.9617900848388672\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [01:04<00:00,  1.17it/s, loss=0.19]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 11917388/12533760 with acc 95.08\n",
            "Dice score: 0.9721086025238037\n",
            "Jaccard index: 0.9717955589294434\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [01:04<00:00,  1.16it/s, loss=0.139]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 11957270/12533760 with acc 95.40\n",
            "Dice score: 0.9738883972167969\n",
            "Jaccard index: 0.973599374294281\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [01:04<00:00,  1.16it/s, loss=0.125]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 11975457/12533760 with acc 95.55\n",
            "Dice score: 0.9750320911407471\n",
            "Jaccard index: 0.9747040271759033\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [01:04<00:00,  1.17it/s, loss=0.107]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 12043759/12533760 with acc 96.09\n",
            "Dice score: 0.9776950478553772\n",
            "Jaccard index: 0.9774475693702698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [01:04<00:00,  1.17it/s, loss=0.0781]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 12064333/12533760 with acc 96.25\n",
            "Dice score: 0.978833794593811\n",
            "Jaccard index: 0.9785579442977905\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [01:04<00:00,  1.17it/s, loss=0.0983]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 11930269/12533760 with acc 95.19\n",
            "Dice score: 0.9712342619895935\n",
            "Jaccard index: 0.971213698387146\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [01:04<00:00,  1.17it/s, loss=0.0885]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 12051084/12533760 with acc 96.15\n",
            "Dice score: 0.9780848622322083\n",
            "Jaccard index: 0.9778265357017517\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [01:04<00:00,  1.16it/s, loss=0.0653]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 12068176/12533760 with acc 96.29\n",
            "Dice score: 0.978995680809021\n",
            "Jaccard index: 0.978705644607544\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [01:04<00:00,  1.17it/s, loss=0.0771]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 12080324/12533760 with acc 96.38\n",
            "Dice score: 0.9794273972511292\n",
            "Jaccard index: 0.9791768193244934\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [01:04<00:00,  1.17it/s, loss=0.0813]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 12066048/12533760 with acc 96.27\n",
            "Dice score: 0.9790149927139282\n",
            "Jaccard index: 0.9786971211433411\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [01:04<00:00,  1.17it/s, loss=0.0718]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 12091576/12533760 with acc 96.47\n",
            "Dice score: 0.9800636172294617\n",
            "Jaccard index: 0.9797869920730591\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [01:04<00:00,  1.17it/s, loss=0.082]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 12092239/12533760 with acc 96.48\n",
            "Dice score: 0.9802860617637634\n",
            "Jaccard index: 0.9799730777740479\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [01:04<00:00,  1.17it/s, loss=0.0904]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 12105120/12533760 with acc 96.58\n",
            "Dice score: 0.9806879758834839\n",
            "Jaccard index: 0.9804051518440247\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [01:04<00:00,  1.17it/s, loss=0.0691]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 12090764/12533760 with acc 96.47\n",
            "Dice score: 0.980121374130249\n",
            "Jaccard index: 0.9798282384872437\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [01:04<00:00,  1.17it/s, loss=0.0769]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 12108169/12533760 with acc 96.60\n",
            "Dice score: 0.9808640480041504\n",
            "Jaccard index: 0.9805751442909241\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [01:04<00:00,  1.16it/s, loss=0.0943]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 12112356/12533760 with acc 96.64\n",
            "Dice score: 0.9810975193977356\n",
            "Jaccard index: 0.9808026552200317\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [01:04<00:00,  1.16it/s, loss=0.0703]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 12113699/12533760 with acc 96.65\n",
            "Dice score: 0.9812005162239075\n",
            "Jaccard index: 0.9808996319770813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [01:04<00:00,  1.17it/s, loss=0.0566]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 12106850/12533760 with acc 96.59\n",
            "Dice score: 0.9809366464614868\n",
            "Jaccard index: 0.9806348085403442\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [01:04<00:00,  1.17it/s, loss=0.0744]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 12111561/12533760 with acc 96.63\n",
            "Dice score: 0.9811488389968872\n",
            "Jaccard index: 0.9808381199836731\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [01:04<00:00,  1.16it/s, loss=0.0506]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 12112594/12533760 with acc 96.64\n",
            "Dice score: 0.9811459183692932\n",
            "Jaccard index: 0.9808481335639954\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [01:04<00:00,  1.17it/s, loss=0.0682]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 12111628/12533760 with acc 96.63\n",
            "Dice score: 0.9811198115348816\n",
            "Jaccard index: 0.9808228015899658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [01:04<00:00,  1.16it/s, loss=0.0712]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 12118010/12533760 with acc 96.68\n",
            "Dice score: 0.9813616275787354\n",
            "Jaccard index: 0.9810709357261658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [01:04<00:00,  1.17it/s, loss=0.0609]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 12116493/12533760 with acc 96.67\n",
            "Dice score: 0.9813151359558105\n",
            "Jaccard index: 0.9810205698013306\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [01:04<00:00,  1.17it/s, loss=0.0792]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 12115856/12533760 with acc 96.67\n",
            "Dice score: 0.9812766909599304\n",
            "Jaccard index: 0.9809854030609131\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [01:04<00:00,  1.16it/s, loss=0.0659]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 12116522/12533760 with acc 96.67\n",
            "Dice score: 0.9813218712806702\n",
            "Jaccard index: 0.9810270071029663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [01:04<00:00,  1.16it/s, loss=0.0512]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 12117896/12533760 with acc 96.68\n",
            "Dice score: 0.9813653230667114\n",
            "Jaccard index: 0.9810713529586792\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Stuff"
      ],
      "metadata": {
        "id": "Na_vUzqMZV3U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "model = unet().to(DEVICE)\n",
        "x, y = next(iter(train_loader))\n",
        "x = x.to(DEVICE)\n",
        "y = y.to(DEVICE)\n",
        "preds = torch.softmax(model(x), 1)\n",
        "_, preds = torch.max(preds, dim=1)\n",
        "preds = preds.type(torch.float)\n",
        "correct = (preds == y).sum()\n",
        "incorrect = (preds != y).sum()\n",
        "total = torch.numel(preds)\n",
        "print(correct)\n",
        "print(incorrect)\n",
        "print(total)\n",
        "print(correct+incorrect)\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7N4xoJGZNq3V",
        "outputId": "c2568a75-6593-4a6c-aeff-7db16743c57a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(19217, device='cuda:0')\n",
            "tensor(98543, device='cuda:0')\n",
            "117760\n",
            "tensor(117760, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model = smp.DeepLabV3Plus(classes=5)\n",
        "# model = model.to(DEVICE)\n",
        "model = torch.load(\"/content/Synthetic_sementation_deeplabv3plus_val_acc=0.9671552777290344_dice=0.9815328121185303_Jaccard=0.9812494516372681\")\n",
        "model.eval()\n",
        "# img, mask = val_dataset[10]\n",
        "# img = img.unsqueeze(0)\n",
        "# img = img.to(DEVICE)\n",
        "# preds = torch.softmax(model(img), 1)\n",
        "# _, preds = torch.max(preds, dim=1)\n",
        "# preds = preds.squeeze(0)\n",
        "# print(img.shape)\n",
        "# print(mask.shape)\n",
        "\n",
        "for i in range(len(val_dataset)):\n",
        "  img, mask = val_dataset[i]\n",
        "  mask = mask.to(DEVICE)\n",
        "  img = img.unsqueeze(0)\n",
        "  img = img.to(DEVICE)\n",
        "  preds = torch.softmax(model(img), 1)\n",
        "  _, preds = torch.max(preds, dim=1)\n",
        "  preds = preds.squeeze(0)\n",
        "  mask = mask.cpu().detach().numpy()\n",
        "  mask[mask == 0] = 107\n",
        "  mask[mask == 1] = 195\n",
        "  mask[mask == 2] = 88\n",
        "  mask[mask == 3] = 70\n",
        "  mask[mask == 4] = 225\n",
        "\n",
        "  # cv2.imwrite(\"/content/drive/MyDrive/Synthetic_masks/ground_truth/\"+str(i)+\".png\", mask)\n",
        "\n",
        "  preds = preds.cpu().detach().numpy()\n",
        "  preds[preds == 0] = 107\n",
        "  preds[preds == 1] = 195\n",
        "  preds[preds == 2] = 88\n",
        "  preds[preds == 3] = 70\n",
        "  preds[preds == 4] = 225\n",
        "  cv2_imshow(mask)\n",
        "  cv2_imshow(preds)\n",
        "  break\n",
        "\n",
        "  # cv2.imwrite(\"/content/drive/MyDrive/Synthetic_masks/torch/\"+str(i)+\".png\", preds)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# mask = mask.cpu().detach().numpy()\n",
        "# mask[mask == 0] = 107\n",
        "# mask[mask == 1] = 195\n",
        "# mask[mask == 2] = 88\n",
        "# mask[mask == 3] = 70\n",
        "# mask[mask == 4] = 225\n",
        "# preds = preds.cpu().detach().numpy()\n",
        "# preds[preds == 0] = 107\n",
        "# preds[preds == 1] = 195\n",
        "# preds[preds == 2] = 88\n",
        "# preds[preds == 3] = 70\n",
        "# preds[preds == 4] = 225\n",
        "\n",
        "# cv2_imshow(mask)\n",
        "# cv2_imshow(preds)"
      ],
      "metadata": {
        "id": "OHdzlbCYaUMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "TSaA8kcebPp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir /content/boards"
      ],
      "metadata": {
        "id": "b52-HsYabQmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openvino\n",
        "from openvino.runtime import Core"
      ],
      "metadata": {
        "id": "8mHRakG6Utui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = torch.load(\"/content/drive/MyDrive/Models/Synthetic_sementation_unet_val_acc=0.9538319706916809_dice=0.9738907814025879_Jaccard=0.9735795259475708\", map_location=torch.device('cpu'))\n",
        "# model.eval()\n",
        "model = smp.DeepLabV3Plus(classes=5)\n",
        "batch = torch.randn(1, 3, 720, 1088)\n",
        "\n",
        "# torch.save(model.state_dict(), f\"Syntheti_deeplabv3plus_val_acc=0,9788\")\n",
        "\n",
        "model = torch.load(\"/content/drive/MyDrive/Models/Synthetic_sementation_deeplabv3plus_val_acc=0.9668765068054199_dice=0.981420636177063_Jaccard=0.9811235666275024\", map_location=torch.device('cpu'))\n",
        "\n",
        "torch.onnx.export(model, batch, \"Synthetic_sementation_deeplabv3plus_val_acc=0.9668765068054199_dice=0.981420636177063_Jaccard=0.9811235666275024.onnx\", export_params=True, opset_version=11)\n",
        "\n",
        "\n",
        "ie = Core()\n",
        "onnx_model = ie.read_model(model=\"Synthetic_sementation_deeplabv3plus_val_acc=0.9668765068054199_dice=0.981420636177063_Jaccard=0.9811235666275024.onnx\")\n",
        "compiled_onnx_model = ie.compile_model(model=onnx_model, device_name=\"CPU\")\n",
        "input_layer = compiled_onnx_model.input(0)\n",
        "output_layer = compiled_onnx_model.output(0)\n",
        "\n",
        "input_layer = compiled_onnx_model.input(0)\n",
        "output_layer = compiled_onnx_model.output(0)\n",
        "\n",
        "num_correct = 0\n",
        "num_pixels = 0\n",
        "dice_score = 0\n",
        "jaccard_idx = 0\n",
        "\n",
        "for i in range(len(val_dataset)):\n",
        "  img, mask = val_dataset[i]\n",
        "\n",
        "  \n",
        "  img = img.unsqueeze(0)\n",
        "  preds = compiled_onnx_model([img])[output_layer]\n",
        "  preds = torch.from_numpy(preds)\n",
        "  preds = torch.softmax(preds, 1)\n",
        "  _, preds = torch.max(preds, dim=1)\n",
        "\n",
        "  preds = preds.type(torch.float)\n",
        "  num_correct += (preds == mask).sum()\n",
        "  num_pixels += torch.numel(preds)\n",
        "  dice_score += (2 * num_correct +1e-8) / (\n",
        "                2 * num_correct + num_pixels - num_correct + 1e-8\n",
        "            )\n",
        "  jaccard_idx += (num_correct + 1e-8) / (\n",
        "                num_correct + (preds != mask).sum()+ 1e-8\n",
        "            )\n",
        "print(\n",
        "        f\"Got {num_correct}/{num_pixels} with acc {num_correct/num_pixels*100:.2f}\"\n",
        "    )\n",
        "print(f\"Dice score: {dice_score/len(val_dataset)}\")\n",
        "\n",
        "jaccard = jaccard_idx/len(val_dataset)\n",
        "print(f\"Jaccard index: {jaccard}\")\n",
        "\n",
        "\n",
        "  # preds = preds.squeeze(0)\n",
        "  # preds = preds.cpu().detach().numpy()\n",
        "  # preds[preds == 0] = 107\n",
        "  # preds[preds == 1] = 195\n",
        "  # preds[preds == 2] = 88\n",
        "  # preds[preds == 3] = 70\n",
        "  # preds[preds == 4] = 225\n",
        "\n",
        "  # cv2.imwrite(\"/content/drive/MyDrive/Synthetic_masks/onnx/\"+str(i)+\".png\", preds)"
      ],
      "metadata": {
        "id": "WJV2vIKLKAE9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179,
          "referenced_widgets": [
            "2136b38ad1264071af9e31bad7ae9d01",
            "1510cc199aa7459db6a4d674074f689f",
            "834ec2c7eaf741efbde02c707b63d378",
            "a55b5272a2e8470cadba478f6ef435a9",
            "e22caac80a494ccfb2c9cf3a324585bc",
            "1ad533cb00644fb78dee828d7ce84975",
            "7e39fc0872ff4470959dc13a1bc48957",
            "b31062964d2e49e4b646978485805e7a",
            "a8fe07243ea84b429d094c629bb5ef9b",
            "136031e5db494d5f858db757709ca4c8",
            "130ec30f81bf4317ac2413964920c09c"
          ]
        },
        "outputId": "e59b9b14-d8ff-445f-f26d-2a613414b91b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-333f7ec4.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/83.3M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2136b38ad1264071af9e31bad7ae9d01"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/segmentation_models_pytorch/base/model.py:16: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if h % output_stride != 0 or w % output_stride != 0:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 12118598/12533760 with acc 96.69\n",
            "Dice score: 0.9810609817504883\n",
            "Jaccard index: 0.9919564723968506\n"
          ]
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUm4RfsPdhNE",
        "outputId": "e7d4ada5-33af-44a1-b197-e870e2a6e1e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: albumentations==1.2.1 in /usr/local/lib/python3.7/dist-packages (1.2.1)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from albumentations==1.2.1) (0.0.4)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==1.2.1) (1.21.6)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==1.2.1) (4.6.0.66)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations==1.2.1) (1.7.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations==1.2.1) (6.0)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==1.2.1) (0.18.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from qudida>=0.0.4->albumentations==1.2.1) (4.1.1)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from qudida>=0.0.4->albumentations==1.2.1) (1.0.2)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations==1.2.1) (2021.11.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations==1.2.1) (1.3.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations==1.2.1) (2.6.3)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations==1.2.1) (2.9.0)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations==1.2.1) (3.2.2)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations==1.2.1) (7.1.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations==1.2.1) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations==1.2.1) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations==1.2.1) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations==1.2.1) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations==1.2.1) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.2.1) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.2.1) (1.2.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting timm\n",
            "  Downloading timm-0.6.11-py3-none-any.whl (548 kB)\n",
            "\u001b[K     |████████████████████████████████| 548 kB 30.5 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 68.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.7/dist-packages (from timm) (1.12.1+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.13.1+cu113)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from timm) (6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7->timm) (4.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->timm) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->timm) (21.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->timm) (4.64.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->timm) (5.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->timm) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->huggingface-hub->timm) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub->timm) (3.9.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->timm) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->timm) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->timm) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->timm) (1.24.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.21.6)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Installing collected packages: huggingface-hub, timm\n",
            "Successfully installed huggingface-hub-0.10.1 timm-0.6.11\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openvino\n",
            "  Using cached openvino-2022.2.0-7713-cp37-cp37m-manylinux_2_27_x86_64.whl (26.8 MB)\n",
            "Requirement already satisfied: numpy<=1.23.1,>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from openvino) (1.21.6)\n",
            "Installing collected packages: openvino\n",
            "Successfully installed openvino-2022.2.0\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "!pip install albumentations==1.2.1\n",
        "!pip install timm\n",
        "!pip install openvino\n",
        "from typing import Any, Callable, List, Optional, Type, Union\n",
        "import timm\n",
        "import os\n",
        "import zipfile\n",
        "import pathlib\n",
        "import sklearn\n",
        "import torchvision\n",
        "import random\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import random_split\n",
        "import torchvision.transforms as tt\n",
        "from torchvision.utils import make_grid\n",
        "import torchvision.transforms.functional as TF\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from types import SimpleNamespace\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import log_loss\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "from google.colab.patches import cv2_imshow\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.optim.swa_utils import AveragedModel, SWALR\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%matplotlib inline\n",
        "\n",
        "os.environ['PYTHONHASHSEED'] = str(27)\n",
        "random.seed(27)\n",
        "np.random.seed(27)\n",
        "torch.manual_seed(27)\n",
        "torch.cuda.manual_seed(27)\n",
        "torch.cuda.manual_seed_all(27)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ResNet"
      ],
      "metadata": {
        "id": "IYEn0-YsnIpY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion: int = 1\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels: int,\n",
        "        out_channels: int,\n",
        "        stride: int = 1,\n",
        "        downsample: Optional[nn.Module] = None\n",
        "    ):\n",
        "      super(BasicBlock, self).__init__()\n",
        "      self.stride = stride\n",
        "      self.downsample = downsample\n",
        "\n",
        "      self.conv1 = nn.Conv2d(in_channels, out_channels, (3, 3), (stride, stride), (1, 1), bias=False)\n",
        "      self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "      self.relu = nn.ReLU(True)\n",
        "      self.conv2 = nn.Conv2d(out_channels, out_channels, (3, 3), (1, 1), (1, 1), bias=False)\n",
        "      self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "      identity = x\n",
        "\n",
        "      out = self.conv1(x)\n",
        "      out = self.bn1(out)\n",
        "      out = self.relu(out)\n",
        "\n",
        "      out = self.conv2(out)\n",
        "      out = self.bn2(out)\n",
        "\n",
        "      if self.downsample is not None:\n",
        "          identity = self.downsample(x)\n",
        "\n",
        "      out = torch.add(out, identity)\n",
        "      out = self.relu(out)\n",
        "\n",
        "      return out\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion: int = 4\n",
        "    def __init__(\n",
        "        self, \n",
        "        in_channels: int, \n",
        "        hidden_dims:int, \n",
        "        stride: int = 1, \n",
        "        identity_downsample: Optional[nn.Module] = None\n",
        "    ):\n",
        "      super(Bottleneck, self).__init__()\n",
        "      self.conv1 = nn.Conv2d(in_channels, hidden_dims, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "      self.bn1 = nn.BatchNorm2d(hidden_dims)\n",
        "      self.conv2 = nn.Conv2d(hidden_dims, hidden_dims, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "      self.bn2 = nn.BatchNorm2d(hidden_dims)\n",
        "      self.conv3 = nn.Conv2d(hidden_dims, hidden_dims * self.expansion, kernel_size=1, stride=1, padding=0, bias=False\n",
        "      )\n",
        "      self.bn3 = nn.BatchNorm2d(hidden_dims * self.expansion)\n",
        "      self.relu = nn.ReLU()\n",
        "      self.identity_downsample = identity_downsample\n",
        "      self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "      identity = x.clone()\n",
        "\n",
        "      x = self.conv1(x)\n",
        "      x = self.bn1(x)\n",
        "      x = self.relu(x)\n",
        "      x = self.conv2(x)\n",
        "      x = self.bn2(x)\n",
        "      x = self.relu(x)\n",
        "      x = self.conv3(x)\n",
        "      x = self.bn3(x)\n",
        "\n",
        "      if self.identity_downsample is not None:\n",
        "          identity = self.identity_downsample(identity)\n",
        "\n",
        "      x += identity\n",
        "      x = self.relu(x)\n",
        "      return x\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, layers, image_channels=3, num_classes=1000):\n",
        "      super(ResNet, self).__init__()\n",
        "      self.in_channels = 64\n",
        "      stages = []\n",
        "      self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "      self.bn1 = nn.BatchNorm2d(64)\n",
        "      self.relu = nn.ReLU()\n",
        "      stages.append(nn.Sequential(self.conv1, self.bn1, self.relu))\n",
        "      self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "      self.layer1 = self._make_layer(\n",
        "        block, layers[0], hidden_dims=64, stride=1\n",
        "      )\n",
        "      stages.append(nn.Sequential(self.maxpool, self.layer1))\n",
        "      self.layer2 = self._make_layer(\n",
        "        block, layers[1], hidden_dims=128, stride=2\n",
        "      )\n",
        "      stages.append(self.layer2)\n",
        "      self.layer3 = self._make_layer(\n",
        "        block, layers[2], hidden_dims=256, stride=2\n",
        "      )\n",
        "      stages.append(self.layer3)\n",
        "      self.layer4 = self._make_layer(\n",
        "        block, layers[3], hidden_dims=512, stride=2\n",
        "      )\n",
        "      stages.append(self.layer4)\n",
        "\n",
        "      self.stages = nn.ModuleList(stages)\n",
        "\n",
        "      self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "      self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "      for stage in self.stages:\n",
        "        x = stage(x)\n",
        "\n",
        "      x = self.avgpool(x)\n",
        "      x = torch.flatten(x, 1)\n",
        "      x = self.fc(x)\n",
        "\n",
        "      return x\n",
        "\n",
        "    def _make_layer(self, block, num_residual_blocks, hidden_dims, stride):\n",
        "      identity_downsample = None\n",
        "      layers = []\n",
        "\n",
        "      if stride != 1 or self.in_channels != hidden_dims * block.expansion:\n",
        "        identity_downsample = nn.Sequential(\n",
        "          nn.Conv2d(self.in_channels, hidden_dims * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
        "          nn.BatchNorm2d(hidden_dims * block.expansion),\n",
        "        )\n",
        "\n",
        "      layers.append(\n",
        "          block(self.in_channels, hidden_dims, stride, identity_downsample)\n",
        "      )\n",
        "\n",
        "      self.in_channels = hidden_dims * block.expansion\n",
        "\n",
        "      for i in range(num_residual_blocks - 1):\n",
        "        layers.append(block(self.in_channels, hidden_dims))\n",
        "\n",
        "      return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "def ResNet18(img_channel=3, num_classes=1000):\n",
        "  return ResNet(BasicBlock, [2, 2, 2, 2], img_channel, num_classes)\n",
        "\n",
        "def ResNet34(img_channel=3, num_classes=1000):\n",
        "  return ResNet(BasicBlock, [3, 4, 6, 3], img_channel, num_classes)\n",
        "\n",
        "def ResNet50(img_channel=3, num_classes=1000):\n",
        "  return ResNet(Bottleneck, [3, 4, 6, 3], img_channel, num_classes)\n",
        "\n",
        "\n",
        "def ResNet101(img_channel=3, num_classes=1000):\n",
        "  return ResNet(Bottleneck, [3, 4, 23, 3], img_channel, num_classes)\n",
        "\n",
        "\n",
        "def ResNet152(img_channel=3, num_classes=1000):\n",
        "  return ResNet(Bottleneck, [3, 8, 36, 3], img_channel, num_classes)"
      ],
      "metadata": {
        "id": "srRVgmdBnLOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MobilenetV2"
      ],
      "metadata": {
        "id": "8MYey7ypC7kA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _make_divisible(v: float, divisor: int, min_value: Optional[int] = None) -> int:\n",
        "    \"\"\"\n",
        "    This function is taken from the original tf repo.\n",
        "    It ensures that all layers have a channel number that is divisible by 8\n",
        "    It can be seen here:\n",
        "    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n",
        "    \"\"\"\n",
        "    if min_value is None:\n",
        "        min_value = divisor\n",
        "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
        "    # Make sure that round down does not go down by more than 10%.\n",
        "    if new_v < 0.9 * v:\n",
        "        new_v += divisor\n",
        "    return new_v\n",
        "\n",
        "class InvertedResidual(nn.Module):\n",
        "  def __init__(\n",
        "      self, in_channels: int, out_channels: int, stride: int, expand_ratio: int, norm_layer: Optional[Callable[..., nn.Module]] = None\n",
        "  ):\n",
        "    super().__init__()\n",
        "    self.stride = stride\n",
        "    if stride not in [1, 2]:\n",
        "        raise ValueError(f\"stride should be 1 or 2 insted of {stride}\")\n",
        "\n",
        "    if norm_layer is None:\n",
        "        norm_layer = nn.BatchNorm2d\n",
        "\n",
        "    hidden_dims = int(round(in_channels * expand_ratio))\n",
        "    self.use_res_connect = ((self.stride == 1) and (in_channels == out_channels))\n",
        "\n",
        "    layers: List[nn.Module] = []\n",
        "    if expand_ratio != 1:\n",
        "      layers.append(\n",
        "        nn.Sequential(\n",
        "          nn.Conv2d(in_channels, hidden_dims, kernel_size=1, stride=1),\n",
        "          nn.BatchNorm2d(hidden_dims),\n",
        "          nn.ReLU6()\n",
        "        ),\n",
        "      )\n",
        "    layers.extend(\n",
        "      [\n",
        "        nn.Sequential(\n",
        "          nn.Conv2d(hidden_dims, hidden_dims, kernel_size=3, stride=self.stride, padding=1, groups=hidden_dims),\n",
        "          nn.BatchNorm2d(hidden_dims),\n",
        "          nn.ReLU6()\n",
        "        ),\n",
        "        nn.Conv2d(hidden_dims, out_channels, 1, 1, 0, bias=False),\n",
        "        norm_layer(out_channels),\n",
        "      ]\n",
        "    )\n",
        "    self.conv = nn.Sequential(*layers)\n",
        "    self.out_channels = out_channels\n",
        "\n",
        "  def forward(self, x):\n",
        "    if self.use_res_connect:\n",
        "      return x + self.conv(x)\n",
        "    else:\n",
        "      return self.conv(x)\n"
      ],
      "metadata": {
        "id": "fgut2mzZC-J9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MobileNetV2(nn.Module):\n",
        "  def __init__(\n",
        "    self,\n",
        "    num_classes: int = 1000,\n",
        "    width_mult: float = 1.0,\n",
        "    inverted_residual_setting: Optional[List[List[int]]] = None,\n",
        "    round_nearest: int = 8,\n",
        "    block: Optional[Callable[..., nn.Module]] = None,\n",
        "    norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
        "    dropout: float = 0.2,\n",
        "  ):\n",
        "    super().__init__()\n",
        "    if block is None:\n",
        "      block = InvertedResidual\n",
        "\n",
        "    if norm_layer is None:\n",
        "      norm_layer = nn.BatchNorm2d\n",
        "\n",
        "    input_channel = 32\n",
        "    last_channel = 1280\n",
        "\n",
        "    if inverted_residual_setting is None:\n",
        "      inverted_residual_setting = [\n",
        "        # t, c, n, s\n",
        "        [1, 16, 1, 1],\n",
        "        [6, 24, 2, 2],\n",
        "        [6, 32, 3, 2],\n",
        "        [6, 64, 4, 2],\n",
        "        [6, 96, 3, 1],\n",
        "        [6, 160, 3, 2],\n",
        "        [6, 320, 1, 1],\n",
        "      ]\n",
        "\n",
        "    if len(inverted_residual_setting) == 0 or len(inverted_residual_setting[0]) != 4:\n",
        "      raise ValueError(\n",
        "        f\"inverted_residual_setting should be non-empty or a 4-element list, got {inverted_residual_setting}\"\n",
        "      )\n",
        "\n",
        "\n",
        "    input_channel = _make_divisible(input_channel * width_mult, round_nearest)\n",
        "    self.last_channel = _make_divisible(last_channel * max(1.0, width_mult), round_nearest)\n",
        "    stages: List[nn.Module] = [\n",
        "      nn.Sequential(\n",
        "        nn.Conv2d(3, input_channel, kernel_size=3, stride=2),\n",
        "        nn.BatchNorm2d(input_channel),\n",
        "        nn.ReLU6()\n",
        "      ),\n",
        "    ]\n",
        "\n",
        "    for t, c, n, s in inverted_residual_setting:\n",
        "      output_channel = _make_divisible(c * width_mult, round_nearest)\n",
        "      stage = []\n",
        "      for i in range(n):\n",
        "        stride = s if i == 0 else 1\n",
        "        stage.append(block(input_channel, output_channel, stride, expand_ratio=t, norm_layer=norm_layer))\n",
        "        input_channel = output_channel\n",
        "      stages.append(nn.Sequential(*stage))\n",
        "\n",
        "\n",
        "    stages.append(\n",
        "      nn.Sequential(\n",
        "          nn.Conv2d(input_channel, self.last_channel, kernel_size=1, stride=stride),\n",
        "          nn.BatchNorm2d(self.last_channel),\n",
        "          nn.ReLU6()\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    self.stages = nn.ModuleList(stages)\n",
        "\n",
        "    # building classifier\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Dropout(p=dropout),\n",
        "        nn.Linear(self.last_channel, num_classes),\n",
        "    )\n",
        "\n",
        "    # weight initialization\n",
        "    for m in self.modules():\n",
        "      if isinstance(m, nn.Conv2d):\n",
        "        nn.init.kaiming_normal_(m.weight, mode=\"fan_out\")\n",
        "        if m.bias is not None:\n",
        "          nn.init.zeros_(m.bias)\n",
        "      elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "        nn.init.ones_(m.weight)\n",
        "        nn.init.zeros_(m.bias)\n",
        "      elif isinstance(m, nn.Linear):\n",
        "        nn.init.normal_(m.weight, 0, 0.01)\n",
        "        nn.init.zeros_(m.bias)\n",
        "\n",
        "  def forward(self, x):\n",
        "    for stage in self.stages:\n",
        "      x = stage(x)\n",
        "    x = nn.functional.adaptive_avg_pool2d(x, (1, 1))\n",
        "    x = torch.flatten(x, 1)\n",
        "    x = self.classifier(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "b7B3D3rHKOM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = MobileNetV2()\n",
        "# batch = torch.randn((1,3,256,256))\n",
        "# res = model(batch)\n",
        "# print(res.shape)"
      ],
      "metadata": {
        "id": "_WIDvwfx-A_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Unet"
      ],
      "metadata": {
        "id": "e8wiajTZbjcD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNetEncoder(ResNet):\n",
        "  def __init__(self, block = BasicBlock, layers = [3, 4, 6, 3], image_channels = 3, out_channels = [3, 64, 64, 128, 256, 512]):\n",
        "    super().__init__(block, layers, image_channels)\n",
        "    self._out_channels = out_channels\n",
        "    self.identity = nn.Identity()\n",
        "  \n",
        "  def forward(self, x):\n",
        "    features = []\n",
        "    x = self.identity(x)\n",
        "    features.append(x)\n",
        "    for stage in self.stages:\n",
        "      x = stage(x)\n",
        "      features.append(x)\n",
        "\n",
        "    return x, features\n",
        "\n",
        "class MobileNetV2Encoder(MobileNetV2):\n",
        "  def __init__(self, out_channels = [3, 32, 16, 24, 32, 64, 96, 160, 320, 1280]):\n",
        "    super().__init__()\n",
        "    self._out_channels = out_channels\n",
        "    self.identity = nn.Identity()\n",
        "  \n",
        "  def forward(self, x):\n",
        "    features = []\n",
        "    x = self.identity(x)\n",
        "    features.append(x)\n",
        "    for stage in self.stages:\n",
        "      x = stage(x)\n",
        "      features.append(x)\n",
        "\n",
        "    return x, features\n",
        "\n",
        "class Conv_block(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "    self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "    self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    x = self.conv1(inputs)\n",
        "    x = self.bn1(x)\n",
        "    x = self.relu(x)\n",
        "\n",
        "    x = self.conv2(x)\n",
        "    x = self.bn2(x)\n",
        "    x = self.relu(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "class Downsample(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv = Conv_block(in_channels, out_channels)\n",
        "    self.pool = nn.MaxPool2d((2, 2))\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    x = self.conv(inputs)\n",
        "    p = self.pool(x)\n",
        "\n",
        "    return x, p\n",
        "\n",
        "\n",
        "class Upsample(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super().__init__()\n",
        "\n",
        "    self.up = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2, padding=0)\n",
        "    self.conv = Conv_block(out_channels + out_channels, out_channels)\n",
        "\n",
        "  def forward(self, inputs, skip):\n",
        "    x = self.up(inputs)\n",
        "    if x.shape != skip.shape:\n",
        "      x = TF.resize(x, size=skip.shape[2:])\n",
        "    x = torch.cat([x, skip], axis=1)\n",
        "    x = self.conv(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self, encoder_out_channels, num_classes=1):\n",
        "    super().__init__()\n",
        "    in_channels = encoder_out_channels[-1]\n",
        "    self.transition = Conv_block(in_channels, in_channels*2)\n",
        "\n",
        "    encoder_out_channels = encoder_out_channels[::-1]\n",
        "    in_channels = in_channels*2\n",
        "    ups = []\n",
        "    for out_channels in encoder_out_channels:\n",
        "      ups.append(Upsample(in_channels, out_channels))\n",
        "      in_channels = out_channels\n",
        "    self.ups = nn.ModuleList(ups)\n",
        "\n",
        "    self.outputs = nn.Conv2d(in_channels, num_classes, kernel_size=1, padding=0)\n",
        "\n",
        "  def forward(self, inputs, skips):\n",
        "    x = self.transition(inputs)\n",
        "\n",
        "\n",
        "    for  up in self.ups:\n",
        "      skip = skips.pop() \n",
        "      x = up(x, skip)\n",
        "\n",
        "\n",
        "    outputs = self.outputs(x)\n",
        "    return outputs\n",
        "\n",
        "class UnetEncoder(nn.Module):\n",
        "  def __init__(self, encoder_out_channels = [64, 128, 256, 512], in_channels=3):\n",
        "    super().__init__()\n",
        "    self._out_channels = encoder_out_channels\n",
        "\n",
        "    downs = []\n",
        "    for out_channels in self._out_channels:\n",
        "      downs.append(Downsample(in_channels, out_channels))\n",
        "      in_channels = out_channels\n",
        "    \n",
        "    self.downs = nn.ModuleList(downs)\n",
        "\n",
        "  def forward(self, x):\n",
        "    skips = []\n",
        "    for down in self.downs:\n",
        "      skip, x = down(x)\n",
        "      skips.append(skip)\n",
        "    \n",
        "    return x, skips\n",
        "\n",
        "class unet(nn.Module):\n",
        "  def __init__(self, encoder_type = UnetEncoder, in_channels=3, num_classes=1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.encoder = encoder_type()\n",
        "    self.decoder = Decoder(self.encoder._out_channels, num_classes)\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    x, skips = self.encoder(inputs)\n",
        "    output = self.decoder(x, skips)\n",
        "    return output"
      ],
      "metadata": {
        "id": "rfxceJrfbm8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = unet()\n",
        "# batch = torch.randn((1,3,512,512))\n",
        "# res = model(batch)\n",
        "# print(res.shape)"
      ],
      "metadata": {
        "id": "Txt7xzsxCh8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Config"
      ],
      "metadata": {
        "id": "omZNc2IOz9J_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed=27):\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "tHuMyXXBb1vg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed_everything()\n",
        "WEIGHT_DECAY = 1e-4\n",
        "LEARNING_RATE = 3e-4\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "BATCH_SIZE = 4\n",
        "NUM_EPOCHS = 20\n",
        "NUM_WORKERS = 2\n",
        "IMAGE_HEIGHT = 720  # 1080 originally\n",
        "IMAGE_WIDTH = 1088  # 1920 originally\n",
        "PIN_MEMORY = True\n",
        "LOAD_MODEL = False"
      ],
      "metadata": {
        "id": "xR_z33Nzt8GD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "a4gv0LFAtuot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zipFile = zipfile.ZipFile('/content/drive/MyDrive/Datasets/synthetic.zip', 'r')\n",
        "zipFile.extractall('dataset')\n",
        "zipFile.close()"
      ],
      "metadata": {
        "id": "ZNJQyTxttyHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SyntheticDataset(Dataset):\n",
        "  def __init__(self, list_path, dir=\"/content/dataset/synthetic\", transform=None ):\n",
        "    self.file_path = list_path\n",
        "    self.dir = dir\n",
        "    self.transforms = transform\n",
        "    self.images_path = self.dir+\"/images\"\n",
        "    self.masks_path = self.dir+\"/masks\"\n",
        "    self.file = open(self.file_path, encoding='utf-8')\n",
        "    self.text = self.file.read()\n",
        "    self.file.close\n",
        "    self.image_descriptions = self.text.split(\"\\n\")\n",
        "    if '' in self.image_descriptions:\n",
        "      self.image_descriptions.remove('')\n",
        "    \n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    img_path = self.images_path+\"/Img_\"+self.image_descriptions[index]+\".jpeg\"\n",
        "    mask_path = self.masks_path+\"/Mask_\"+self.image_descriptions[index]+\".png\"\n",
        "    image = np.array(Image.open(img_path).convert(\"RGB\"))\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    mask = np.array(Image.open(mask_path).convert(\"L\"))\n",
        "    mask[mask == 107] = 0\n",
        "    mask[mask == 195] = 1\n",
        "    mask[mask == 88] = 2\n",
        "    mask[mask == 70] = 3\n",
        "    mask[mask == 225] = 4\n",
        "    \n",
        "    if self.transforms is not None:\n",
        "      augmentations = self.transforms(image=image, mask=mask)\n",
        "      image = augmentations[\"image\"]\n",
        "      mask = augmentations[\"mask\"]\n",
        "    return image, mask\n",
        "\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.image_descriptions)"
      ],
      "metadata": {
        "id": "m2eAZ1q5t397"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed_everything()\n",
        "mean = [0.5585, 0.6353, 0.6439]\n",
        "std = [0.1218, 0.1545, 0.1860]\n",
        "train_transforms1 = A.Compose(\n",
        "        [\n",
        "            A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
        "            A.Rotate(limit=35, p=1.0),\n",
        "            A.HorizontalFlip(p=0.9),\n",
        "            A.VerticalFlip(p=0.9),\n",
        "            A.Normalize(\n",
        "                mean=mean,\n",
        "                std=std,\n",
        "                max_pixel_value=255.0,\n",
        "            ),\n",
        "            ToTensorV2(),\n",
        "        ],\n",
        "    )\n",
        "\n",
        "train_transforms2 = A.Compose(\n",
        "        [\n",
        "            A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
        "            # A.RGBShift(r_shift_limit=25, g_shift_limit=25, b_shift_limit=25),\n",
        "            # A.Blur(blur_limit=5, p=0.7),\n",
        "            # A.RandomBrightnessContrast(p=0.5),\n",
        "            # A.ChannelShuffle(p=0.7),\n",
        "            # A.Solarize(threshold=128, p=0.5),\n",
        "            # A.GaussNoise(),\n",
        "            # A.InvertImg(p=0.7),\n",
        "            A.Normalize(\n",
        "                mean=mean,\n",
        "                std=std,\n",
        "                max_pixel_value=255.0,\n",
        "            ),\n",
        "            ToTensorV2(),\n",
        "        ],\n",
        "    )\n",
        "\n",
        "train_transforms3 = A.Compose(\n",
        "        [\n",
        "            A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
        "            # A.RGBShift(r_shift_limit=25, g_shift_limit=25, b_shift_limit=25),\n",
        "            # A.Blur(blur_limit=5, p=0.7),\n",
        "            # A.RandomBrightnessContrast(p=0.5),\n",
        "            # A.ChannelShuffle(p=0.7),\n",
        "            A.Solarize(threshold=128, p=0.5),\n",
        "            A.GaussNoise(),\n",
        "            A.InvertImg(p=0.7),\n",
        "            A.Normalize(\n",
        "                mean=mean,\n",
        "                std=std,\n",
        "                max_pixel_value=255.0,\n",
        "            ),\n",
        "            ToTensorV2(),\n",
        "        ],\n",
        "    )\n",
        "val_transforms = A.Compose(\n",
        "        [\n",
        "            A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
        "            A.Normalize(\n",
        "                mean=mean,\n",
        "                std=std,\n",
        "                max_pixel_value=255.0,\n",
        "            ),\n",
        "            ToTensorV2(),\n",
        "        ],\n",
        "    )"
      ],
      "metadata": {
        "id": "M1jTrOoAuAaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed_everything()\n",
        "train_dataset1 = SyntheticDataset(\n",
        "        list_path = \"/content/dataset/synthetic/lists/train_lst.txt\",\n",
        "        transform=train_transforms1,\n",
        "    )\n",
        "\n",
        "train_dataset2 = SyntheticDataset(\n",
        "        list_path = \"/content/dataset/synthetic/lists/train_lst.txt\",\n",
        "        transform=train_transforms2,\n",
        "    )\n",
        "\n",
        "train_dataset3 = SyntheticDataset(\n",
        "        list_path = \"/content/dataset/synthetic/lists/train_lst.txt\",\n",
        "        transform=train_transforms3,\n",
        "    )\n",
        "\n",
        "train_dataset = torch.utils.data.ConcatDataset([train_dataset1, train_dataset2, train_dataset3])\n",
        "\n",
        "train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=PIN_MEMORY,\n",
        "        shuffle=True,\n",
        "    )\n",
        "\n",
        "val_dataset = SyntheticDataset(\n",
        "        list_path = \"/content/dataset/synthetic/lists/val_lst.txt\",\n",
        "        transform=val_transforms,\n",
        "    )\n",
        "\n",
        "val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=PIN_MEMORY,\n",
        "        shuffle=False,\n",
        "    )"
      ],
      "metadata": {
        "id": "cf8krQJOuC5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Assets"
      ],
      "metadata": {
        "id": "H7Zdtp4ZuHUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_accuracy(loader, model, device=\"cuda\"):\n",
        "    num_correct = 0\n",
        "    num_pixels = 0\n",
        "    dice_score = 0\n",
        "    jaccard_idx = 0\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            preds = torch.softmax(model(x), 1)\n",
        "            _, preds = torch.max(preds, dim=1)\n",
        "            preds = preds.type(torch.float)\n",
        "            num_correct += (preds == y).sum()\n",
        "            num_pixels += torch.numel(preds)\n",
        "            dice_score += (2 * num_correct +1e-8) / (\n",
        "                2 * num_correct + num_pixels - num_correct + 1e-8\n",
        "            )\n",
        "            jaccard_idx += (num_correct + 1e-8) / (\n",
        "                num_correct + (preds != y).sum()+ 1e-8\n",
        "            )\n",
        "    acc = num_correct/num_pixels\n",
        "    print(\n",
        "        f\"Got {num_correct}/{num_pixels} with acc {num_correct/num_pixels*100:.2f}\"\n",
        "    )\n",
        "    dice = dice_score/len(loader)\n",
        "    print(f\"Dice score: {dice_score/len(loader)}\")\n",
        "\n",
        "    jaccard = jaccard_idx/len(loader)\n",
        "    print(f\"Jaccard index: {jaccard}\")\n",
        "    model.train()\n",
        "\n",
        "    return acc, dice, jaccard"
      ],
      "metadata": {
        "id": "xr97E4PSuGle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training"
      ],
      "metadata": {
        "id": "oiCPxfzkuLK6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_fn(loader, model, optimizer, loss_fn, scaler):\n",
        "    seed_everything()\n",
        "    loop = tqdm(loader)\n",
        "\n",
        "    for batch_idx, (data, targets) in enumerate(loop):\n",
        "        data = data.to(device=DEVICE)\n",
        "        targets = targets.type(torch.LongTensor)\n",
        "        targets = targets.to(device=DEVICE)\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "          predictions = model(data)\n",
        "          loss = loss_fn(predictions, targets)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        loop.set_postfix(loss=loss.item())"
      ],
      "metadata": {
        "id": "RDhk9VpccMqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed_everything()\n",
        "weights = torch.tensor([0.4, 1.9, 0.7, 0.4, 1.5], device=DEVICE)\n",
        "ClassicUnet = unet(encoder_type = UnetEncoder, num_classes=5)\n",
        "ClassicUnet = ClassicUnet.to(DEVICE)\n",
        "loss_fn = nn.CrossEntropyLoss(weight = weights)\n",
        "optimizer = optim.Adam(ClassicUnet.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "\n",
        "writer = SummaryWriter(\"/content/boards/classicunet\")\n",
        "step = 0\n",
        "\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  train_fn(train_loader, ClassicUnet, optimizer, loss_fn, scaler)\n",
        "\n",
        "\n",
        "  val_acc, dice_score, jaccard_idx = check_accuracy(val_loader, ClassicUnet, device=DEVICE)\n",
        "\n",
        "\n",
        "  writer.add_scalar(\"Validation accuracy\", val_acc, global_step=step)\n",
        "  writer.add_scalar(\"Dice score\", dice_score, global_step=step)\n",
        "  writer.add_scalar(\"Jaccard index\", jaccard_idx, global_step=step) \n",
        "  step += 1\n",
        "  \n",
        "writer.close()\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qp4w9RXjuNBv",
        "outputId": "24e123dd-e315-42eb-a810-1236138ae22e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [01:41<00:00,  1.35s/it, loss=0.736]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 11275616/12533760 with acc 89.96\n",
            "Dice score: 0.9413691163063049\n",
            "Jaccard index: 0.9413865804672241\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [01:34<00:00,  1.26s/it, loss=0.575]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 11190497/12533760 with acc 89.28\n",
            "Dice score: 0.9376745223999023\n",
            "Jaccard index: 0.9377182722091675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [01:34<00:00,  1.27s/it, loss=0.467]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 11030288/12533760 with acc 88.00\n",
            "Dice score: 0.9235711693763733\n",
            "Jaccard index: 0.9255033731460571\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [01:34<00:00,  1.26s/it, loss=0.385]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 9366227/12533760 with acc 74.73\n",
            "Dice score: 0.8349645733833313\n",
            "Jaccard index: 0.8419570922851562\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [01:34<00:00,  1.26s/it, loss=0.201]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 11826185/12533760 with acc 94.35\n",
            "Dice score: 0.9683389663696289\n",
            "Jaccard index: 0.9679786562919617\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [01:34<00:00,  1.25s/it, loss=0.172]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 11747745/12533760 with acc 93.73\n",
            "Dice score: 0.9642733335494995\n",
            "Jaccard index: 0.9639766216278076\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [01:34<00:00,  1.26s/it, loss=0.139]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 11850362/12533760 with acc 94.55\n",
            "Dice score: 0.9681392908096313\n",
            "Jaccard index: 0.9679662585258484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [01:34<00:00,  1.25s/it, loss=0.113]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 11992076/12533760 with acc 95.68\n",
            "Dice score: 0.9756700992584229\n",
            "Jaccard index: 0.9753456115722656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [01:34<00:00,  1.25s/it, loss=0.11]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 11785158/12533760 with acc 94.03\n",
            "Dice score: 0.9644649028778076\n",
            "Jaccard index: 0.9645889401435852\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [01:33<00:00,  1.25s/it, loss=0.1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 12039095/12533760 with acc 96.05\n",
            "Dice score: 0.9778341054916382\n",
            "Jaccard index: 0.9775028228759766\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [01:33<00:00,  1.25s/it, loss=0.187]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 10558999/12533760 with acc 84.24\n",
            "Dice score: 0.9138653874397278\n",
            "Jaccard index: 0.912909209728241\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [01:34<00:00,  1.25s/it, loss=0.114]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 11866440/12533760 with acc 94.68\n",
            "Dice score: 0.9689728021621704\n",
            "Jaccard index: 0.9689285159111023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [01:33<00:00,  1.25s/it, loss=0.0951]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 11997128/12533760 with acc 95.72\n",
            "Dice score: 0.9762411117553711\n",
            "Jaccard index: 0.9758787751197815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [01:33<00:00,  1.25s/it, loss=0.0838]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 12056785/12533760 with acc 96.19\n",
            "Dice score: 0.9785735607147217\n",
            "Jaccard index: 0.9782595634460449\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [01:33<00:00,  1.25s/it, loss=0.0772]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 12024406/12533760 with acc 95.94\n",
            "Dice score: 0.9768967032432556\n",
            "Jaccard index: 0.9766157865524292\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [01:33<00:00,  1.25s/it, loss=0.0936]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 9397192/12533760 with acc 74.98\n",
            "Dice score: 0.8483207821846008\n",
            "Jaccard index: 0.8514636754989624\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [01:34<00:00,  1.26s/it, loss=0.22]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 11044173/12533760 with acc 88.12\n",
            "Dice score: 0.9309117794036865\n",
            "Jaccard index: 0.9311120510101318\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [01:34<00:00,  1.26s/it, loss=0.0976]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 11925417/12533760 with acc 95.15\n",
            "Dice score: 0.9726930856704712\n",
            "Jaccard index: 0.9723756909370422\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [01:33<00:00,  1.25s/it, loss=0.0778]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 12070803/12533760 with acc 96.31\n",
            "Dice score: 0.9791549444198608\n",
            "Jaccard index: 0.9788599014282227\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [01:33<00:00,  1.25s/it, loss=0.0755]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 12076403/12533760 with acc 96.35\n",
            "Dice score: 0.9791728258132935\n",
            "Jaccard index: 0.9789113402366638\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "DLlYAoaabEMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir /content/boards/classicunet"
      ],
      "metadata": {
        "id": "wXKrRsxObEvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed_everything()\n",
        "weights = torch.tensor([0.4, 1.9, 0.7, 0.4, 1.5], device=DEVICE)\n",
        "UnetWithResNetEncoder = unet(encoder_type = ResNetEncoder, num_classes=5)\n",
        "UnetWithResNetEncoder = UnetWithResNetEncoder.to(DEVICE)\n",
        "loss_fn = nn.CrossEntropyLoss(weight = weights)\n",
        "optimizer = optim.Adam(UnetWithResNetEncoder.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "\n",
        "writer = SummaryWriter(\"/content/boards/resnet\")\n",
        "step = 0\n",
        "\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  train_fn(train_loader, UnetWithResNetEncoder, optimizer, loss_fn, scaler)\n",
        "\n",
        "\n",
        "  val_acc, dice_score, jaccard_idx = check_accuracy(val_loader, UnetWithResNetEncoder, device=DEVICE)\n",
        "\n",
        "\n",
        "  writer.add_scalar(\"Validation accuracy\", val_acc, global_step=step)\n",
        "  writer.add_scalar(\"Dice score\", dice_score, global_step=step)\n",
        "  writer.add_scalar(\"Jaccard index\", jaccard_idx, global_step=step) \n",
        "  step += 1\n",
        "  \n",
        "writer.close()\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "pO_c-tdHxYuo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "844e6370-c6d3-4c23-9b9d-9349ef3150de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [00:36<00:00,  2.03it/s, loss=1.92]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 3269114/12533760 with acc 26.08\n",
            "Dice score: 0.4453437924385071\n",
            "Jaccard index: 0.46349892020225525\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [00:36<00:00,  2.05it/s, loss=1.88]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 3412863/12533760 with acc 27.23\n",
            "Dice score: 0.45821642875671387\n",
            "Jaccard index: 0.4762350618839264\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [00:37<00:00,  2.03it/s, loss=1.86]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 3416089/12533760 with acc 27.26\n",
            "Dice score: 0.4585648775100708\n",
            "Jaccard index: 0.47655874490737915\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [00:36<00:00,  2.04it/s, loss=1.83]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 3408360/12533760 with acc 27.19\n",
            "Dice score: 0.45778408646583557\n",
            "Jaccard index: 0.4758162498474121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [00:38<00:00,  1.94it/s, loss=1.77]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 3296807/12533760 with acc 26.30\n",
            "Dice score: 0.4487047493457794\n",
            "Jaccard index: 0.4665164351463318\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [00:36<00:00,  2.04it/s, loss=1.73]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 3411188/12533760 with acc 27.22\n",
            "Dice score: 0.4582372307777405\n",
            "Jaccard index: 0.4762048125267029\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [00:37<00:00,  2.02it/s, loss=1.66]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 3405462/12533760 with acc 27.17\n",
            "Dice score: 0.45765650272369385\n",
            "Jaccard index: 0.4756571650505066\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [00:36<00:00,  2.05it/s, loss=1.56]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 3414220/12533760 with acc 27.24\n",
            "Dice score: 0.45834091305732727\n",
            "Jaccard index: 0.4763602018356323\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [00:36<00:00,  2.04it/s, loss=1.47]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 3459774/12533760 with acc 27.60\n",
            "Dice score: 0.4623924493789673\n",
            "Jaccard index: 0.48034054040908813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [00:38<00:00,  1.96it/s, loss=1.4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 5807357/12533760 with acc 46.33\n",
            "Dice score: 0.6467040777206421\n",
            "Jaccard index: 0.6569055318832397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [00:37<00:00,  2.02it/s, loss=1.28]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 6894432/12533760 with acc 55.01\n",
            "Dice score: 0.7097415924072266\n",
            "Jaccard index: 0.7189478278160095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [00:36<00:00,  2.06it/s, loss=1.18]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 8932702/12533760 with acc 71.27\n",
            "Dice score: 0.8274720907211304\n",
            "Jaccard index: 0.8304508924484253\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [00:36<00:00,  2.03it/s, loss=1.1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 9706785/12533760 with acc 77.45\n",
            "Dice score: 0.8619572520256042\n",
            "Jaccard index: 0.8650549054145813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [00:36<00:00,  2.04it/s, loss=0.984]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 10554446/12533760 with acc 84.21\n",
            "Dice score: 0.9054545760154724\n",
            "Jaccard index: 0.9067991971969604\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [00:38<00:00,  1.94it/s, loss=0.902]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 10775451/12533760 with acc 85.97\n",
            "Dice score: 0.9171605706214905\n",
            "Jaccard index: 0.917889416217804\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [00:36<00:00,  2.04it/s, loss=0.805]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 10737312/12533760 with acc 85.67\n",
            "Dice score: 0.9166252613067627\n",
            "Jaccard index: 0.9170735478401184\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [00:36<00:00,  2.03it/s, loss=0.744]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 10787394/12533760 with acc 86.07\n",
            "Dice score: 0.9186697006225586\n",
            "Jaccard index: 0.9191606044769287\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [00:37<00:00,  2.02it/s, loss=0.762]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 10728603/12533760 with acc 85.60\n",
            "Dice score: 0.9168728590011597\n",
            "Jaccard index: 0.9170849323272705\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [00:36<00:00,  2.03it/s, loss=0.643]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 10838727/12533760 with acc 86.48\n",
            "Dice score: 0.9219534993171692\n",
            "Jaccard index: 0.9222301244735718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [00:37<00:00,  1.99it/s, loss=0.597]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 10880189/12533760 with acc 86.81\n",
            "Dice score: 0.9233851432800293\n",
            "Jaccard index: 0.923737645149231\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir /content/boards/resnet"
      ],
      "metadata": {
        "id": "tIwg4ZpAbJTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed_everything()\n",
        "weights = torch.tensor([0.4, 1.9, 0.7, 0.4, 1.5], device=DEVICE)\n",
        "UnetWithMobileNetV2Encoder = unet(encoder_type = MobileNetV2Encoder, num_classes=5)\n",
        "UnetWithMobileNetV2Encoder = UnetWithMobileNetV2Encoder.to(DEVICE)\n",
        "loss_fn = nn.CrossEntropyLoss(weight = weights)\n",
        "optimizer = optim.Adam(UnetWithMobileNetV2Encoder.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "\n",
        "writer = SummaryWriter(\"/content/boards/mobilenetv2\")\n",
        "step = 0\n",
        "\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  train_fn(train_loader, UnetWithMobileNetV2Encoder, optimizer, loss_fn, scaler)\n",
        "\n",
        "\n",
        "  val_acc, dice_score, jaccard_idx = check_accuracy(val_loader, UnetWithMobileNetV2Encoder, device=DEVICE)\n",
        "\n",
        "\n",
        "  writer.add_scalar(\"Validation accuracy\", val_acc, global_step=step)\n",
        "  writer.add_scalar(\"Dice score\", dice_score, global_step=step)\n",
        "  writer.add_scalar(\"Jaccard index\", jaccard_idx, global_step=step) \n",
        "  step += 1\n",
        "  \n",
        "writer.close()\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfSiH3mlafeC",
        "outputId": "76cc234e-ad43-43b2-8332-5948eccf3587"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [00:47<00:00,  1.57it/s, loss=1.09]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 8775901/12533760 with acc 70.02\n",
            "Dice score: 0.80437171459198\n",
            "Jaccard index: 0.8126125335693359\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [00:47<00:00,  1.58it/s, loss=1.01]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 8830281/12533760 with acc 70.45\n",
            "Dice score: 0.8071077466011047\n",
            "Jaccard index: 0.815250039100647\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [00:46<00:00,  1.60it/s, loss=0.963]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 8859921/12533760 with acc 70.69\n",
            "Dice score: 0.808976411819458\n",
            "Jaccard index: 0.8169353008270264\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [00:46<00:00,  1.60it/s, loss=0.9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 8748645/12533760 with acc 69.80\n",
            "Dice score: 0.8010371923446655\n",
            "Jaccard index: 0.8100195527076721\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [00:46<00:00,  1.62it/s, loss=0.836]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 8931984/12533760 with acc 71.26\n",
            "Dice score: 0.8126356601715088\n",
            "Jaccard index: 0.8204694390296936\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [00:46<00:00,  1.62it/s, loss=0.777]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 9252236/12533760 with acc 73.82\n",
            "Dice score: 0.8310174345970154\n",
            "Jaccard index: 0.8374994397163391\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [00:46<00:00,  1.63it/s, loss=0.725]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 9150734/12533760 with acc 73.01\n",
            "Dice score: 0.8260908722877502\n",
            "Jaccard index: 0.8327156901359558\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [00:47<00:00,  1.60it/s, loss=0.672]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 9022202/12533760 with acc 71.98\n",
            "Dice score: 0.8193233013153076\n",
            "Jaccard index: 0.8262869119644165\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [00:46<00:00,  1.63it/s, loss=0.628]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 9011517/12533760 with acc 71.90\n",
            "Dice score: 0.818800687789917\n",
            "Jaccard index: 0.8257733583450317\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [00:46<00:00,  1.63it/s, loss=0.588]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 9032029/12533760 with acc 72.06\n",
            "Dice score: 0.8197404742240906\n",
            "Jaccard index: 0.826711893081665\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [00:46<00:00,  1.62it/s, loss=0.548]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 9042642/12533760 with acc 72.15\n",
            "Dice score: 0.8204469680786133\n",
            "Jaccard index: 0.8273395299911499\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [00:46<00:00,  1.62it/s, loss=0.513]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 9029110/12533760 with acc 72.04\n",
            "Dice score: 0.8194764852523804\n",
            "Jaccard index: 0.8264937996864319\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [00:45<00:00,  1.63it/s, loss=0.482]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 9049820/12533760 with acc 72.20\n",
            "Dice score: 0.8208000063896179\n",
            "Jaccard index: 0.8276822566986084\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [00:46<00:00,  1.62it/s, loss=0.457]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 9039520/12533760 with acc 72.12\n",
            "Dice score: 0.8203004598617554\n",
            "Jaccard index: 0.8271961212158203\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [00:46<00:00,  1.63it/s, loss=0.428]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 9062675/12533760 with acc 72.31\n",
            "Dice score: 0.821506142616272\n",
            "Jaccard index: 0.828344464302063\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [00:46<00:00,  1.62it/s, loss=0.407]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 9057611/12533760 with acc 72.27\n",
            "Dice score: 0.8212207555770874\n",
            "Jaccard index: 0.8280788660049438\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [00:46<00:00,  1.63it/s, loss=0.391]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 9032695/12533760 with acc 72.07\n",
            "Dice score: 0.819736123085022\n",
            "Jaccard index: 0.8267197608947754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [00:46<00:00,  1.63it/s, loss=0.367]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 9060187/12533760 with acc 72.29\n",
            "Dice score: 0.8213868141174316\n",
            "Jaccard index: 0.8282291889190674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [00:45<00:00,  1.63it/s, loss=0.348]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 9059025/12533760 with acc 72.28\n",
            "Dice score: 0.8213143348693848\n",
            "Jaccard index: 0.8281625509262085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [00:47<00:00,  1.58it/s, loss=0.331]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 9054263/12533760 with acc 72.24\n",
            "Dice score: 0.8210656046867371\n",
            "Jaccard index: 0.8279259204864502\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir /content/boards/mobilenetv2"
      ],
      "metadata": {
        "id": "9DzWwSs6bMIS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}